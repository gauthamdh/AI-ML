{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83PQZDNAmzHq"
   },
   "source": [
    "Training deeper networks using residual connections. In this notebook, a 50-layer residual network popularly known as ResNet50, is built from scratch and trained on a custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rh655XXGJo2U",
    "outputId": "5d78c0ca-319c-446b-dde6-01ab5aa33b75"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M8vgAFZ1hNua"
   },
   "outputs": [],
   "source": [
    "def block_identity(X, num_filters, k):\n",
    "\n",
    "    num1, num2, num3 = num_filters\n",
    "    X_skip = X\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters=num1, kernel_size=(1,1), padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters=num2, kernel_size=(k,k), padding='same')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters=num3, kernel_size=(1,1), padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "\n",
    "    X = tf.keras.layers.Add()([X_skip, X])\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mxs53KEfO1Ht"
   },
   "outputs": [],
   "source": [
    "def block_conv(X, num_filters, k, s):\n",
    "\n",
    "    num1, num2, num3 = num_filters\n",
    "    X_skip = X\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters=num1, kernel_size=(1,1), strides=(s,s), padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters=num2, kernel_size=(k,k), strides=(1,1), padding='same')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters=num3, kernel_size=(1,1), strides=(1,1), padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "\n",
    "    X_skip = tf.keras.layers.Conv2D(filters=num3, kernel_size=(1,1), strides=(s,s), padding='valid')(X_skip)\n",
    "    X_skip = tf.keras.layers.BatchNormalization()(X_skip)\n",
    "\n",
    "    X = tf.keras.layers.Add()([X_skip, X])\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "\n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pS0S7ABBW0sX"
   },
   "outputs": [],
   "source": [
    "def resnet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \n",
    "    X_input = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    X = tf.keras.layers.ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(64, (7, 7), strides = (2, 2))(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    X = block_conv(X, num_filters = [64, 64, 256], k = 3, s=1)\n",
    "    X = block_identity(X, num_filters=[64, 64, 256], k=3)\n",
    "    X = block_identity(X, num_filters=[64, 64, 256], k=3)\n",
    "\n",
    "    X = block_conv(X, num_filters = [128, 128, 512], k = 3, s = 2)\n",
    "    X = block_identity(X, num_filters=[128, 128, 512], k=3)\n",
    "    X = block_identity(X, num_filters=[128, 128, 512], k=3)\n",
    "    X = block_identity(X, num_filters=[128, 128, 512], k=3)\n",
    "\n",
    "    X = block_conv(X, num_filters = [256, 256, 1024], k = 3, s = 2)\n",
    "    X = block_identity(X, num_filters=[256, 256, 1024], k=3)\n",
    "    X = block_identity(X, num_filters=[256, 256, 1024], k=3)\n",
    "    X = block_identity(X, num_filters=[256, 256, 1024], k=3)\n",
    "    X = block_identity(X, num_filters=[256, 256, 1024], k=3)\n",
    "    X = block_identity(X, num_filters=[256, 256, 1024], k=3)\n",
    "\n",
    "    X = block_conv(X, num_filters=[512, 512, 2048], k=3, s=2)\n",
    "    X = block_identity(X, num_filters=[512, 512, 2048], k=3)\n",
    "    X = block_identity(X, num_filters=[512, 512, 2048], k=3)\n",
    "\n",
    "    X = tf.keras.layers.AveragePooling2D(pool_size=(2,2))(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(classes, activation='softmax')(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qyjU_XfLbqXq"
   },
   "outputs": [],
   "source": [
    "model = resnet50(input_shape=(64,64,3), classes=6)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PBZix0cMcLu8",
    "outputId": "46c86862-0203-4df5-891d-272e5822f0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 64, 64, 3) (120, 64, 64, 3)\n",
      "(1080, 6)\n"
     ]
    }
   ],
   "source": [
    "nclasses = 6\n",
    "import h5py\n",
    "\n",
    "def load_dataset():\n",
    "    train_set = h5py.File('/content/train_signs.h5', \"r\")\n",
    "    x_train_orig = np.array(train_set[\"train_set_x\"][:])\n",
    "    y_train_orig = np.array(train_set[\"train_set_y\"][:])\n",
    "\n",
    "    test_set = h5py.File('/content/test_signs.h5', \"r\")\n",
    "    x_test_orig = np.array(test_set[\"test_set_x\"][:])\n",
    "    y_test_orig = np.array(test_set[\"test_set_y\"][:])\n",
    "\n",
    "    labels = np.array(test_set[\"list_classes\"][:])\n",
    "    \n",
    "    return x_train_orig, x_test_orig, y_train_orig, y_test_orig, labels\n",
    "\n",
    "x_train_orig, x_test_orig, y_train_orig, y_test_orig, labels = load_dataset()\n",
    "x_train = x_train_orig/255.\n",
    "x_test = x_test_orig/255.\n",
    "print(x_train.shape, x_test.shape)\n",
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# x_train = x_train/255.\n",
    "# x_test = x_test/255.\n",
    "y_train_oh = tf.one_hot(y_train_orig, depth=nclasses, on_value=1., off_value=0.)\n",
    "y_test_oh = tf.one_hot(y_test_orig, depth=nclasses, on_value=1., off_value=0.)\n",
    "print(y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KpmebJDNeEe6",
    "outputId": "5af14ebf-9758-490f-9b6f-ae95108d0d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_test_oh[0])\n",
    "print(y_test_orig[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GyCv2EMzeNkC",
    "outputId": "e5ab4072-d80e-4b44-9def-0d49a79353ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "34/34 [==============================] - 2s 59ms/step - loss: 2.0660e-04 - accuracy: 1.0000\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - 2s 57ms/step - loss: 1.1544e-04 - accuracy: 1.0000\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 2.8389e-04 - accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 2.4149e-04 - accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 5.9791e-05 - accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 5.3049e-05 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 7.1671e-05 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - 2s 57ms/step - loss: 6.7012e-05 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - 2s 57ms/step - loss: 6.0164e-05 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 8.5955e-05 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - 2s 56ms/step - loss: 3.6883e-05 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - 2s 57ms/step - loss: 5.2521e-05 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - 2s 57ms/step - loss: 4.6305e-05 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - 2s 57ms/step - loss: 4.2320e-05 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - 2s 57ms/step - loss: 3.1759e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f16021c8e10>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_oh, epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMquzx35kYVI",
    "outputId": "ac63e121-b4c7-4c0a-ec2e-1d228de8ff12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1759 - accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17588749527931213, 0.9583333134651184]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND2rs1i_lRtB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ResNets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
